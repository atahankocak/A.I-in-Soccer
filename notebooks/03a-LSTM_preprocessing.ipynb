{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very Humble Beginings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this third notebook, I plan to get into Recurrent Neural Network Model - LSTM. I want to try predicting player coordinates in the next n seconds by looking at last n seconds. \n",
    "\n",
    "However, I wish to get into some preprocessing/feature engineering before starting to build the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usual suspects!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "\n",
    "# file format\n",
    "import json\n",
    "\n",
    "# dictionary\n",
    "from collections import defaultdict\n",
    "\n",
    "# preprocessing\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# models\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "\n",
    "#layers\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "# incase we needs these\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n",
    "# visualizations\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas setup\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 4000)\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's bring the all events dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read in dataset\n",
    "events = pd.read_csv(\"../../csv_files/AI_in_Soccer/02-eventsAll.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I like to work with pipelines. In my opinion, they are easy to trace and good way of saving time in long runs. \n",
    "\n",
    "In my experince, a pipline completes the project by evolving into a product. It may feel something like building a lego structure with proper staircase to the 2nd floor. It avoids the question of how the little Lego man goes to the second floor of the building we just put together (I love [Lego](https://www.lego.com/en-us)!). On the least, i kept thinking that whenevet I see a lego city building.\n",
    "\n",
    "Now, let's build the pipeline piece by piece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "I need some selections. \n",
    "\n",
    "First, I select a match. I am not going with `gameweek` here, because it may have multiple matches of the same team if the there is a postponed match previously. Also, this selection goes with development level only. The user level access would already have the match data loaded.\n",
    "\n",
    "Second, I select a player. I must construct a dictionary with player id's as the values of the players names. Because, nobody will remember a player by its player id in this dataset. There can be players' names (possibly a drop down in the final web application) based on the teams in the match.\n",
    "\n",
    "Third, I sort and filter. Why sort? Because, the sequence of events is important for this prediction model. LSTM works on sequential data. So, I pay special attention to pick the train and test portions in sequential order. \n",
    "\n",
    "Why filter? Because I need the time and the coordinate features for LSTM. The `event` is for the final pipeline and the `matchPeriod` is for the train/test split.\n",
    "\n",
    "Also, the momentum of every match is different from the previous and next matches. It is due to differences such as:\n",
    " - Importance of the match\n",
    " - Toughness of the opponent\n",
    " - Stamina level of the players\n",
    " - Home vs away match factor\n",
    " - The weather effect \n",
    "\n",
    "To honor these differences, I stick with one match. How? Well, train & validate in first period and test in second period, hence the fourth: Split.\n",
    "\n",
    "\n",
    "Let's define the name: id dictionary and then the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the players data\n",
    "players={}\n",
    "with open('../../Data/AI_in_Soccer/players.json') as json_data:\n",
    "    players = json.load(json_data)\n",
    "\n",
    "# scan the \"players\" and deveop the name:id dictionary\n",
    "player_names = {}\n",
    "for i in range(0, len(players)):    \n",
    "    player_names[players[i]['shortName']] = int(players[i]['wyId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the initilizer\n",
    "def dataset_init(df, matchid, player_name, period):\n",
    "    \n",
    "    # 1 - Pick a match\n",
    "    match_df= df[df['matchId'] ==  matchid]\n",
    "    \n",
    "    # 2 - Pick a player\n",
    "    player_id = player_names[player_name]\n",
    "    player_df = match_df[match_df['playerId'] ==  player_id].reset_index(drop=True) \n",
    "    \n",
    "    # 3 - Sort the dataframe and filter\n",
    "    player_df.sort_values(by=['gameweek', 'matchId', 'matchPeriod', 'eventSec'], inplace=True)\n",
    "    df = player_df[['matchPeriodNum', 'event', 'eventSec', 'x_start', 'y_start']]\n",
    "    \n",
    "    # 4 - Split the dataframe\n",
    "    train_test_df = df[df.matchPeriodNum == period]\n",
    "    \n",
    "    return train_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the deep-prep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A - ultimate dataset prep tool.          \n",
    "def deep_prep(df):\n",
    "    \n",
    "    # 1) round the seconds\n",
    "    df['eventSecRound'] = df['eventSec'].round(0)\n",
    "    \n",
    "    # 2) drop duplicate seconds (low possibility, but a life saver in later stages)\n",
    "    df.drop_duplicates(subset='eventSecRound', keep=\"first\", inplace=True)\n",
    "\n",
    "    # 3) calculate and set the deltas\n",
    "    df['sec_delta'] = df.eventSecRound.diff().round(0).shift(-1)\n",
    "    df['x_delta'] = df.x_start.diff().shift(-1)\n",
    "    df['y_delta'] = df.y_start.diff().shift(-1)\n",
    "\n",
    "    # 4) calculate the unit delta\n",
    "    df['x_unit'] = df.x_delta / df.sec_delta\n",
    "    df['y_unit'] = df.y_delta / df.sec_delta\n",
    "    \n",
    "    # 5) add a temporary label \n",
    "    df['temp_label'] = 1\n",
    "    \n",
    "    # 6) sanity check #1\n",
    "    print(df.shape[0])\n",
    "    \n",
    "    # 7) add event seconds to get the dataset to 1 second intervals\n",
    "    df = (df.merge(how='right', on='eventSecRound', \n",
    "                               right = pd.DataFrame({'eventSecRound':np.arange(df.iloc[0]['eventSecRound'], \n",
    "                                                             df.iloc[-1]['eventSecRound'] + 1, 1)})).\n",
    "     sort_values('eventSecRound').\n",
    "     reset_index().\n",
    "     drop(['index'], axis=1))\n",
    "    \n",
    "    # 8) fill the temp label NaN s with 0 for later use in processes \n",
    "    df['temp_label'].fillna(0, inplace=True)\n",
    "\n",
    "    # 9) sanity check #2\n",
    "    print(df.temp_label.sum())\n",
    "    \n",
    "    # 10) fill NaN's in both fields\n",
    "    value_copy(df, 'x_unit')\n",
    "    value_copy(df, 'y_unit')\n",
    "    \n",
    "    # 11) initiate the new ball coordinate fields\n",
    "    df['x_ball'] = 0.0\n",
    "    df['y_ball'] = 0.0\n",
    "    \n",
    "    # 12) add the observations between gaps by differences equally seperated by unit factor\n",
    "    temp_coord(df, 'x_ball', 'x_start', 'x_unit')\n",
    "    temp_coord(df, 'y_ball', 'y_start', 'y_unit')\n",
    "    \n",
    "    # 13) create new fields for final coordinates\n",
    "    df['x_ball_plus'] = df['x_ball'] + df['x_unit']\n",
    "    df['x_ball_minus'] = df['x_ball'] - df['x_unit']\n",
    "    df['y_ball_plus'] = df['y_ball'] + df['y_unit']\n",
    "    df['y_ball_minus'] = df['y_ball'] - df['y_unit']\n",
    "    \n",
    "    # 14a) generate x coordinates\n",
    "    df['x_player'] = 0.0\n",
    "    df['x_player'][0] = df['x_start'][0]\n",
    "    for i in range(1, len(df['temp_label'])):\n",
    "        if df['temp_label'][i] == 0:\n",
    "            df['x_player'][i] = np.random.uniform(df['x_ball_plus'][i], df['x_ball_minus'][i])\n",
    "        else:\n",
    "            df['x_player'][i] = df['x_start'][i]\n",
    "\n",
    "    # 14b) generate y coordinates\n",
    "    df['y_player'] = 0.0\n",
    "    df['y_player'][0] = df['y_start'][0]\n",
    "    for i in range(1, len(df['temp_label'])):\n",
    "        if df['temp_label'][i] == 0:\n",
    "            df['y_player'][i] = np.random.uniform(df['y_ball_plus'][i], df['y_ball_minus'][i])\n",
    "        else:\n",
    "            df['y_player'][i] = df['y_start'][i]\n",
    "            \n",
    "    # and the big boy!        \n",
    "    return df[['event', 'x_player', 'y_player']]\n",
    "\n",
    "\n",
    "# B - fill NaN's with the appropriate value\n",
    "def value_copy(df, column):\n",
    "    df[column] = np.where(~df[column].isnull(), df[column], 100000)\n",
    "    for i in range(1, len(df[column])):\n",
    "        if df[column][i] == 100000:\n",
    "            df[column][i] = df[column][i-1]\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "# C - add temp dummy coordinates\n",
    "def temp_coord(df, temp, static, unit):\n",
    "    df[temp] = 0.0\n",
    "    df[temp][0] = df[static][0]\n",
    "    for i in range(1, len(df.temp_label)):\n",
    "        if df.temp_label[i] == 1:\n",
    "            df[temp][i] = df[static][i]\n",
    "        else:\n",
    "            df[temp][i] = df[temp][i-1] + df[unit][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ultimate goal is creating regular timesteps in one second intervals, a sequetial reproduction of observations.  The original dataset does not have regular intervals. It has events and the events are apart from eachother in irregular timesteps. I need equally spaced sequences. Since these sequnces will be used to place the player on the pitch, I need to preserve the randomness of the soccer player movement as well. Let's go over the steps in the process item by item:\n",
    "\n",
    "    1) The first step is rounding the seconds since I am setting the interval space to one second in this version.\n",
    "    2) The rounded seconds end up as duplicates rarely. Once that happens, the process crashes. To avoid that, I drop the dedupe and keep the first to avoid the error.\n",
    "    3) Then calculate the differences between rounded seconds and respective coordinates. I shift them up by one, so I can use them to create that many rows for equally spaced time sequnce.\n",
    "    4) Get the unit change in coordinates given the number of seconds between 2 events.\n",
    "    5) Create a temporary label to use later (\"temp_label\"). The timing of this step is important. Because, I will zero the ones related to dummy coordinates for selective purposes. It will be clear later.\n",
    "    6) A check of the number of rows prior to sequential repopulation of rows.\n",
    "    7) This is where I repopulate the the datarame by one second intervals.\n",
    "    8) Once the repopulation is completed, the temp_label's in those will be NaN's (or zeros). If theya re not zeros, I make sure they are.\n",
    "    9) Check the previously populated temp_label sum (where temp_label == 1) and compare to the initial datasets row counts. They need to be equal to each other. Again, this is for a selective purpose which I will explain in later stages.\n",
    "    10) Next I make sure that x and y unit changes are identical along the observations between events. As I added sequential one second intervals betweens rounded event seconds, I need to perform a similar activity for the coordinates. Since we are looking at a player's events data with given coordinates at each event, we can safely assume that the player moves between those coordinates during the time between the same two events. based on that assumption,  the process knows how many units it needs to add to the previous coordinate to create the next one in the sequence. I know I sounded like a time travel problem, but stay with me!\n",
    "    11) Create the ball coordiante column and ...\n",
    "    12) The item 10 leads to the calculation of the ball coordinates! They are linear. The process looks at the temp_label and checks if it is \"0\". If it is \"0\" then it creates a row and uses unit changes to assign new coordnaites for that row. If it is \"1\", it leaves it alone. What do I mean by that? It creates linear ball movement. The ball will travel in a straight line (with the excption of \"bend it like Beckham\" cases) between 2 events. There it is, item 10 (unit changes) is added to the \"x_start\" and \"y_start\" in each interval between events to create the movement of the ball in a sequential order. Now I have a fake ball that is moving around to direct the player around the field! However, it is just a fake ball...with a purpose (fake ball paradox).\n",
    "    13) A soccer player is not likely to move on the pitch in straight lines all the time. He may do that in a case of sprint (without the ball). But that is about it. There will be some sort of randomness involved in his activities. That randomness is partially directed by the ball (the fake ball paradox!). In other words, the ball we created is only a representation of the mass/momentum of the real ball. And I use that to randomize the player's movements. How? Uniform distribution! The uniform distribution needs borders. In this item, I create those borders. Imagine a line of boxes sequentially ordered along the line between 2 events (fake ball!). The number of the boxes are equal to the number of rows created in item 12. And finally..\n",
    "    14) I pick random points from each uniform distriution and create the player movement by connecting those coordinates. Yes, the randomness may have larger differences that one unit between each seconds, but know this, soccer players are fast! They can move about 3 yards in a given second. Well, it is very unlikely to encounter a case where their artifical movement is not realistic. But to ease the pain I can add some distance limit between these coordinates if it makes you happy...in version 2.0! For real, I will look at it at a later stage. The time is running out.\n",
    "\n",
    "That is about it!\n",
    "\n",
    "A and B are the helping processes and they are pretty self explanatory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ready!\n",
    "\n",
    "I go ahead and start the fun. I want to pick a match of Arsenal (who else!) and then get the midfielder \"G. Xhaka\". Then, I initilize. Finally, I prepare the training and test sets and save the to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initilize\n",
    "train_df = dataset_init(events, 2500040, \"G. Xhaka\", 1)\n",
    "test_df = dataset_init(events, 2500040, \"G. Xhaka\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Quick comment:** I decide to use a midfielder as my test subject. Good news is that the midfield players are involved with a lot of events given their nature and high ball skill level. The bad news is that they are everywhere on the football pitch in a given game! They help defense, support attack, sprint forward, run back, and move box to box. All the midfielder activity leads to a bigger challange for the prediction model. No problem, it would not be fun if it was easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "87.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atahankocak/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/atahankocak/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/atahankocak/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/atahankocak/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/atahankocak/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/atahankocak/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/atahankocak/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/atahankocak/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/atahankocak/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/atahankocak/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "62.0\n"
     ]
    }
   ],
   "source": [
    "# and deep-prep\n",
    "train_df = deep_prep(train_df)\n",
    "test_df = deep_prep(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2791, 3)\n",
      "(3043, 3)\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv\n",
    "train_df.to_csv(\"../../csv_files/AI_in_Soccer/LSTM_train.csv\")\n",
    "test_df.to_csv(\"../../csv_files/AI_in_Soccer/LSTM_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM training is done in the final notebook. Since it is trained on 1st match period or the previous match, it is a part of the final product (pipeline). See you in the 04! But please check 03b for event predictors preprocessing and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
